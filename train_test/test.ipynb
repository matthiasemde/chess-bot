{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([95013, 2, 6, 8, 8])\n",
      "torch.Size([95013])\n",
      "torch.Size([95013, 768])\n"
     ]
    }
   ],
   "source": [
    "input_data = torch.load('input_data.pt').cuda()\n",
    "input_data_check = torch.load('input_data_check.pt').cuda()\n",
    "output_data = torch.load('output_data.pt').cuda()\n",
    "\n",
    "input_data = input_data.to(torch.float32)#.view(-1, 12, 8, 8)\n",
    "output_data = output_data.to(torch.float32)\n",
    "\n",
    "print(input_data.shape)\n",
    "print(output_data.shape)\n",
    "centipawn_std = torch.std(output_data)\n",
    "output_data = output_data / centipawn_std\n",
    "\n",
    "input_data = input_data.reshape(input_data.shape[0], -1)\n",
    "input_data_check = input_data_check.reshape(input_data_check.shape[0], -1)\n",
    "print(input_data.shape)\n",
    "\n",
    "n_data = input_data.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(644.9344, device='cuda:0')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centipawn_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.0301, device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(-14.8930, device='cuda:0')\n",
      "tensor(14.8930, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(torch.mean(output_data))\n",
    "print(torch.std(output_data))\n",
    "print(torch.min(output_data))\n",
    "print(torch.max(output_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(torch.nn.Linear(768, 1)).cuda()\n",
    "model = torch.nn.Sequential(torch.nn.Linear(768, 10),torch.nn.ReLU(),torch.nn.Linear(10, 1)).cuda()\n",
    "#model = torch.nn.Sequential(torch.nn.Linear(768, 10),torch.nn.ReLU(),torch.nn.Linear(10, 10),torch.nn.ReLU(),torch.nn.Linear(10, 1))\n",
    "# model = torch.nn.Sequential(torch.nn.Conv2d(12, 16, 3,padding='same'),torch.nn.ReLU(),torch.nn.Conv2d(16, 16, 3,stride=5),torch.nn.ReLU(),torch.nn.Flatten(), torch.nn.Linear(64, 16),torch.nn.ReLU(), torch.nn.Linear(16, 1)).cuda()\n",
    "\n",
    "# torchsummary.summary(model, (12, 8, 8))\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0117806196212769\n",
      "0.2703206241130829\n",
      "0.20132943987846375\n",
      "0.17992885410785675\n",
      "0.17029914259910583\n",
      "0.1643807590007782\n",
      "0.160278782248497\n",
      "0.15751144289970398\n",
      "0.1554950624704361\n",
      "0.1538955271244049\n",
      "0.15269945561885834\n",
      "0.15156467258930206\n",
      "0.15073274075984955\n",
      "0.150009885430336\n",
      "0.14941875636577606\n",
      "0.14878053963184357\n",
      "0.14814381301403046\n",
      "0.14776568114757538\n",
      "0.1473497450351715\n",
      "0.14703112840652466\n"
     ]
    }
   ],
   "source": [
    "model = model.to(torch.float32)\n",
    "for i in range(20000):\n",
    "    loss = torch.mean(torch.square(model(input_data)[:,0]-output_data))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    model.zero_grad()\n",
    "    if i%1000 == 0:     \n",
    "        print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checksum:  0.5304069519042969\n"
     ]
    }
   ],
   "source": [
    "print(\"checksum: \", (model(input_data_check)-model.state_dict()[\"2.bias\"]).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.state_dict().keys()\n",
    "\n",
    "params = []\n",
    "\n",
    "for layer in range(2):\n",
    "    w_key = str(layer*2)+'.weight'\n",
    "    b_key = str(layer*2)+'.bias'\n",
    "    W = torch.cat((model.state_dict()[w_key].T, model.state_dict()[b_key].reshape(1, -1)), dim=0)\n",
    "    params += W.T.reshape(-1).tolist()\n",
    "\n",
    "with open(\"weights.txt\", \"w\") as text_file:\n",
    "    for i,p in enumerate(params):\n",
    "        if i%12 == 0:\n",
    "            text_file.write('\\n')\n",
    "        text_file.write(\"{:.4f}, \".format(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_idx = range(0,15)#random.sample(range(1,n_data),10)\n",
    "# print(torch.cat([model(input_data[batch_idx,:])[:,0].view(-1,1),output_data[batch_idx].view(-1,1)] , dim=1)*centipawn_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = model.cpu()\n",
    "\n",
    "# model_int8 = torch.ao.quantization.quantize_dynamic(\n",
    "#     model,  # the original model\n",
    "#     {torch.nn.Linear},  # a set of layers to dynamically quantize\n",
    "#     dtype=torch.qint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss = torch.mean(torch.square(model(input_data.cpu())[:,0]-output_data.cpu()))\n",
    "# loss_int8 = torch.mean(torch.square(model_int8(input_data.cpu())[:,0]-output_data.cpu()))\n",
    "\n",
    "# print(loss.item(), loss_int8.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.state_dict()['0.weight'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.mean(torch.square(input_data.cpu() @ model.state_dict()['0.weight'][0] + model.state_dict()['0.bias'][0] - output_data.cpu()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # print(list(model.parameters()))\n",
    "# w = model_int8.state_dict()['0._packed_params._packed_params'][0][0]\n",
    "\n",
    "# print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.mean(torch.square(input_data.cpu() @ model_int8.state_dict()['0._packed_params._packed_params'][0][0]))# + model_int8.state_dict()['0._packed_params._packed_params'][1] - output_data.cpu()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
